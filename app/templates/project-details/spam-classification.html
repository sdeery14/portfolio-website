<h1>Spam Detection using Natural Language Processing</h1>
        
<h2 id="overview">Overview</h2>
<p>This project aims to create a model that can accurately classify emails as either spam or ham using Natural Language Processing (NLP) techniques. By analyzing the subject and body of emails, we build various feature sets and utilize machine learning algorithms to detect spam with high accuracy.</p>

<h2 id="introduction">Introduction</h2>
<p>Spam emails are a significant threat to both individuals and organizations. They often carry malware that can damage or gain unauthorized access to systems, leading to financial loss and compromised data. This project focuses on using NLP to classify emails as spam or ham to help mitigate these risks. We use the Enron-Spam dataset, which contains emails from Enron employees, categorized into 'ham' and 'spam'.</p>

<h2 id="data">Data</h2>
<p>The dataset used is the Enron-Spam dataset. It includes 5172 emails, stored in folders labeled 'ham' (legitimate emails) and 'spam' (spam emails).</p>

<h2 id="libraries-used">Libraries Used</h2>
<ul>
    <li><code>os</code>, <code>sys</code>: For file handling and system operations.</li>
    <li><code>random</code>, <code>pandas</code>: For data manipulation and organization.</li>
    <li><code>nltk</code>: For text processing and tokenization.</li>
    <li><code>matplotlib.pyplot</code>, <code>seaborn</code>, <code>wordcloud</code>: For data visualization.</li>
    <li><code>sklearn</code>: For building and evaluating machine learning models.</li>
</ul>

<h2 id="data-retrieval-and-exploration">Data Retrieval and Exploration</h2>
<p>We started by extracting emails from the dataset and storing them in a list called <code>raw_data_list</code>. Each email was labeled as either 'ham' or 'spam'. We used various visualizations, such as word clouds and bar plots, to understand the distribution and common words in the dataset.</p>
<img src="{{ url_for('static', filename='spam-classification/wordcloud.png') }}" alt="Wordcloud" class="project-image">
<p>The image above is the wordcloud from the Enron-Spam dataset.</p>
<img src="{{ url_for('static', filename='spam-classification/spam-ham-distribution.png') }}" alt="Spam vs. Ham Distribution" class="project-image">
<p>Below is the distribution of spam versus ham emails in the dataset.</p>

<h2 id="data-preprocessing">Data Preprocessing</h2>
<p>Preprocessing steps included:</p>
<ul>
    <li><strong>Shuffling Data:</strong> Ensuring random selection of training and test sets.</li>
    <li><strong>Balancing the Dataset:</strong> Creating a balanced dataset with equal numbers of 'ham' and 'spam' emails.</li>
    <li><strong>Tokenization:</strong> Breaking down the email text into tokens (words).</li>
    <li><strong>Stop Words Removal:</strong> Removing common words that do not contribute to classification.</li>
</ul>

<h2 id="feature-engineering">Feature Engineering</h2>
<p>We created several features to aid in the classification:</p>
<ul>
    <li><strong>Unigram Features:</strong> Frequency of individual words in the emails.</li>
    <li><strong>Verb Phrase Features:</strong> Extracting verb phrases to capture calls to action often found in spam.</li>
    <li><strong>Punctuation Features:</strong> Counting punctuation marks which might indicate spam.</li>
</ul>

<h2 id="model-training-and-evaluation">Model Training and Evaluation</h2>
<p>We used the Naive Bayes classifier for model training. To evaluate the model, we applied cross-validation and generated confusion matrices to visualize the performance. The evaluation metrics included accuracy, precision, recall, and F1 scores.</p>

<h2 id="results">Results</h2>
<p>The models were evaluated using different feature sets:</p>
<ul>
    <li><strong>Unigram Features:</strong> Achieved classification accuracy around 95.42%.</li>
    <li><strong>Verb Phrase Features:</strong> Less accurate compared to unigrams.</li>
    <li><strong>Punctuation Features:</strong> Second most accurate model after unigrams.</li>
    <li><strong>Combination of Verb Phrases and Punctuation:</strong> Improved accuracy over individual use.</li>
</ul>
<p>The balanced dataset models performed slightly better, achieving around 96.33% accuracy. Below is the confusion matrix from the balanced dataset.</p>
<img src="{{ url_for('static', filename='spam-classification/confusion-matrix.png') }}" alt="Confusion Matrix" class="project-image">

<h2 id="conclusion">Conclusion</h2>
<p>Natural language processing is effective in detecting spam emails. Our best model, based on unigram frequency distributions, achieved high accuracy. Future improvements could include integrating more grammatical elements, such as noun phrases and adjective phrases, into the feature sets.</p>

<h2 id="authors">Authors</h2>
<p><strong>Devyn Hughes</strong></p>
<p><strong>Sean Deery</strong></p>

<h2 id="usage">Usage</h2>
<ol>
    <li>Clone the repository: <code>git clone https://github.com/sdeery14/spam-classification.git</code></li>
    <li>Navigate to the project directory: <code>cd spam-classification</code></li>
    <li>Install requirements: <code>pip install -r requirements.txt</code></li>
    <li>Run the spam classification: <code>python notebooks/spam-classification.py</code></li>
</ol>

<h2 id="license">License</h2>
<p>This project is licensed under the MIT License - see the <a href="LICENSE">LICENSE</a> file for details.</p>